# Learning-Data-Science
Here I learn data science related stuff like Machine Learning, Deep Learning, Natural Language Processing and more
# Learning about Machine Learning & their Subcategories
Machine Learning – Subcategories

1. Supervised Learning (uses labeled data)
Regression (predict continuous values)

Linear Regression

Polynomial Regression

Ridge/Lasso/ElasticNet Regression

Support Vector Regression (SVR)

Decision Tree Regression

Random Forest Regression

Gradient Boosting Regression (XGBoost, LightGBM, CatBoost)

Classification (predict discrete classes)

Logistic Regression

k-Nearest Neighbors (k-NN)

Support Vector Machines (SVM)

Naïve Bayes (Gaussian, Multinomial, Bernoulli)

Decision Trees

Random Forest

Gradient Boosting Classifiers (XGBoost, LightGBM, CatBoost)

Neural Network Classifiers

Ensemble Methods (Bagging, Boosting, Stacking, Voting Classifiers)

2. Unsupervised Learning (uses unlabeled data)

Clustering

k-Means

Hierarchical Clustering

DBSCAN (Density-Based Spatial Clustering)

Gaussian Mixture Models (GMMs)

Mean-Shift Clustering

Spectral Clustering

Dimensionality Reduction

Principal Component Analysis (PCA)

Linear Discriminant Analysis (LDA)

t-SNE (t-distributed Stochastic Neighbor Embedding)

UMAP (Uniform Manifold Approximation and Projection)

Autoencoders (Deep Learning-based)

Association Learning

Apriori Algorithm

Eclat Algorithm

FP-Growth

Density Estimation

Kernel Density Estimation (KDE)

Bayesian Methods

3. Reinforcement Learning (RL)

Basic RL

Markov Decision Processes (MDPs)

Dynamic Programming (Policy/Value Iteration)

Monte Carlo Methods

Temporal Difference Learning

Model-Free RL

Q-Learning

SARSA (State-Action-Reward-State-Action)

Policy Gradient Methods

REINFORCE

Actor-Critic Methods

Proximal Policy Optimization (PPO)

Deep Deterministic Policy Gradient (DDPG)

Soft Actor-Critic (SAC)

Deep Reinforcement Learning

Deep Q-Networks (DQN)

AlphaGo-style RL (Monte Carlo Tree Search + Deep Networks)

Multi-Agent RL

Cooperative RL

Competitive RL

4. Semi-Supervised Learning (mix of labeled + unlabeled data)

Self-Training

Co-Training

Graph-Based Semi-Supervised Learning

Semi-Supervised GANs (Generative Adversarial Networks)

5. Self-Supervised Learning

Contrastive Learning (SimCLR, MoCo)

Masked Language Models (BERT, RoBERTa)

Masked Autoencoders (MAE for vision)

Next-Token Prediction (GPT family)

6. Online Learning / Incremental Learning

Stochastic Gradient Descent (SGD)

Online Perceptron

Adaptive Algorithms (AdaBoost in streaming, Hoeffding Trees)

7. Evolutionary / Genetic Algorithms

Genetic Algorithms (GA)

Genetic Programming (GP)

Evolution Strategies (ES)

Particle Swarm Optimization (PSO)

8. Ensemble Learning

Bagging (Bootstrap Aggregation)

Boosting (AdaBoost, Gradient Boosting, XGBoost)

Stacking (Meta-Learners)

Blending

Voting (Hard/Soft Voting Classifiers)

9. Bayesian Learning

Bayesian Networks

Bayesian Inference

Gaussian Processes (GPs)

Variational Inference

Markov Chain Monte Carlo (MCMC)

10. Deep Learning (subset of ML, but separate in practice)

Feedforward Neural Networks (ANNs)

Convolutional Neural Networks (CNNs)

Recurrent Neural Networks (RNNs, LSTMs, GRUs)

Transformer Models (BERT, GPT, Vision Transformers)

Generative Models

GANs (Generative Adversarial Networks)

VAEs (Variational Autoencoders)

Diffusion Models

✅ So the main ML categories are:

Supervised Learning

Unsupervised Learning

Reinforcement Learning

Semi-Supervised Learning

Self-Supervised Learning

Online/Incremental Learning

Evolutionary/Genetic Algorithms

Ensemble Learning

Bayesian Learning

Deep Learning
# Exhaustive List of Supervised Learning Algorithms
1. Regression Algorithms (predict continuous values)

Linear Models

Linear Regression

Ridge Regression

Lasso Regression

ElasticNet

Bayesian Linear Regression

Logistic Regression (technically classification but sometimes used in regression contexts)

Non-linear / Tree-based Models

Decision Tree Regression

Random Forest Regression

Gradient Boosting Regression (XGBoost, LightGBM, CatBoost, HistGB)

Extra Trees Regression

Kernel & Support-based Models

Support Vector Regression (SVR)

Kernel Ridge Regression

Instance-based Models

k-Nearest Neighbors Regression (k-NN)

Probabilistic / Bayesian Models

Gaussian Process Regression (GPR)

Bayesian Ridge Regression

Neural Network-based Regression

Multi-Layer Perceptron (MLP) Regression

Deep Learning Regression Models

2. Classification Algorithms (predict discrete classes)

Linear Models

Logistic Regression

Linear Discriminant Analysis (LDA)

Quadratic Discriminant Analysis (QDA)

Tree-based Models

Decision Tree Classifier

Random Forest Classifier

Gradient Boosting Classifier (XGBoost, LightGBM, CatBoost, HistGB)

Extra Trees Classifier

Support / Kernel-based Models

Support Vector Machines (SVM) / Kernel SVM

Instance-based Models

k-Nearest Neighbors (k-NN)

Probabilistic Models

Naïve Bayes (Gaussian, Multinomial, Bernoulli, Complement)

Bayesian Networks

Neural Networks

Multi-Layer Perceptron (MLP) Classifier

Convolutional Neural Networks (for image classification)

Recurrent Neural Networks (for sequential classification)

Ensemble Methods

Bagging (Bootstrap Aggregating)

Boosting (AdaBoost, Gradient Boosting)

Stacking / Blending / Voting Classifiers

XGBoost / LightGBM / CatBoost Ensembles

Other Specialized Classifiers

Perceptron

Ridge Classifier

Passive-Aggressive Classifier

Nearest Centroid

Linear SVC

One-vs-Rest / One-vs-One strategies (meta-strategies for multiclass)
